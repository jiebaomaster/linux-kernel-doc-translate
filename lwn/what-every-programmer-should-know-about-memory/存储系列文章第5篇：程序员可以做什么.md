# 6 存储系列文章第5篇：程序员可以做什么

> 原文链接 [Memory part 5: What programmers can do](https://lwn.net/Articles/255364/)，by [Ulrich Drepper](https://www.codeblueprint.co.uk/)，2007-10-23

在前面几节的描述之后，很明显，程序员有很多很多机会来影响程序的性能，无论是积极的还是消极的。我们将从最底层的物理RAM访问和一级缓存开始，包括影响内存处理的操作系统功能性，从头开始，全面介绍这些机会。

## 6.1 绕过缓存

当产生数据而没有立即消耗数据时，内存存储操会先读取一条完整的缓存行，然后修改缓存的数据，这对性能是有害的。这种操作将那些不会很快被使用的数据装入缓存，而将可能会再次需要的数据从缓存中推出。对于大型数据结构尤其如此，比如矩阵，它们是先进行完整填充然后再使用的。在矩阵的填充最后一个元素之前，大型矩阵的数据大小会使得其第一个元素从缓存中清除，使第一个元素的写缓存失效。

处理器为上述的情况提供了非临时性（non-temporal）写操作支持。在本文中，非临时性意味着数据不会很快被重用，因此没有理由缓存它。这些非临时写操作不会读取缓存行然后修改它，而是直接将新内容写入内存。

这听起来可能开销很高，但并不一定如此。处理器将尝试使用写合并write-combining（见第3.3.3节）来填充整个缓存行。如果写合并成功，则根本不需要内存读取操作。对于x86和x86-64体系结构，gcc提供了许多内部函数：

``` c
#include <emmintrin.h>
void _mm_stream_si32(int *p, int a);
void _mm_stream_si128(int *p, __m128i a);
void _mm_stream_pd(double *p, __m128d a);

#include <xmmintrin.h>
void _mm_stream_pi(__m64 *p, __m64 a);
void _mm_stream_ps(float *p, __m128 a);

#include <ammintrin.h>
void _mm_stream_sd(double *p, __m128d a);
void _mm_stream_ss(float *p, __m128 a);
```

如果一次性处理大量数据，这些指令的使用效率最高。数据从内存中加载，在一个或多个步骤中处理，然后写回内存。数据“流”过处理器，这就是gcc内部函数命名的由来。

内存地址必须对齐到8字节或16字节。在使用多媒体扩展的代码中，可以用这些非临时性版函数代替普通的`_mm_store_*`函数。在9.1节的矩阵乘法代码中，我们不这样做，因为写入的值在很短的时间内被重用。在这个例子中，使用流指令是没有用的。关于此代码的更多信息见第6.2.1节。

处理器的写合并缓冲区只能在一定时间内保留对缓存行进行部分写操作的请求。为了使写合并能起作用，通常需要将修改一条高速缓存行的所有指令逐条地发布。示例如下：

``` c
#include <emmintrin.h>
void setbytes(char *p, int c)
{
  __m128i i = _mm_set_epi8(c, c, c, c,
                           c, c, c, c,
                           c, c, c, c,
                           c, c, c, c);
  _mm_stream_si128((__m128i *)&p[0], i);
  _mm_stream_si128((__m128i *)&p[16], i);
  _mm_stream_si128((__m128i *)&p[32], i);
  _mm_stream_si128((__m128i *)&p[48], i);
}
```

假设指针p对齐正确，则对该函数的调用会将p所寻址的高速缓存行的所有字节设置为c。写合并逻辑能看到接下去的四个 movntdq 指令，并且仅在执行完最后一条指令后才向内存发出写命令。总而言之，这种代码序列不仅避免在写入之前读取缓存行，而且还避免了用可能很快就不需要的数据污染缓存。在某些情况下，这可以带来巨大的好处。使用此技术的日常代码的一个例子是C运行时中的memset函数，它应该在处理大型块时使用类似于上面的代码序列。

一些体系结构提供了专门的解决方案。PowerPC体系结构定义了dcbz指令，该指令可用于清除整个高速缓存行。该指令实际上并未绕过高速缓存，因为它仍然为执行结果分配了高速缓存行，但是没有从内存中读取任何数据来填充高速缓存。它比非临时存储指令有更多限制，因为它只能将高速缓存行设置为全零，并且会污染高速缓存（如果数据是非临时的），但是不需要借助写合并逻辑来实现功能。

为了查看非临时指令的实际效果，我们创建了如下测试，用于测量以二维数组形式组织的矩阵的写入性能。编译器将矩阵M[i][j]按逐行顺序放置在内存中，左边的下标 i 索引了矩阵的行，右边的下标 j 索引了行中的每个元素。测试程序以两种方式遍历这个矩阵：第一种是在内循环遍历i行中的每个元素；第二种是在内循环中遍历j列中的每个元素。这意味着我们使用了如图6.1所示的两种行为。

![Figure 6.1: Matrix Access Pattern](https://static.lwn.net/images/cpumemory/cpumemory.36.png)
**图 6.1: 矩阵访问模式**

我们测量初始化3000×3000矩阵所需的时间。为了了解内存的行为，我们使用不使用高速缓存的存储指令。我们使用IA-32处理器上的“non-temporal hint”做这个测试。为了比较，我们还测量了普通存储指令的情况。结果见表6.1。

|  | 内部遍历行 | 内部遍历列 |
| --- | --- | --- |
| 普通指令 | 0.048s | 0.127s |
| 非临时指令 | 0.048s | 0.160s |
**表6.1：矩阵初始化消耗时间**

对于确实使用高速缓存的普通写入，我们看到了预期的结果：如果顺序使用内存，将获得更好的结果。顺序使用时，整个操作耗时0.048s，即大约750MB/s，而大概相当于随机访问的情况下，这需要0.127s（大约280MB/s）。因为我们使用的矩阵足够大，缓存实际上只对内存中顺序存放的行有效，则按列遍历矩阵时缓存实际上是无效的。

我们在这里主要感兴趣的部分是绕过缓存的写操作。令人惊讶的是，测试中顺序访问的情况，绕过缓存与使用缓存的速度一样快。出现这种情况的原因是，处理器进行了上文所述的写合并。此外，非临时写入的内存排序规则限制被放宽了：程序需要显式插入内存屏障（x86和x86-64处理器的sfence指令）。这意味着处理器拥有更大的自由写回数据，从而尽可能地利用可用带宽。

在内部循环中按列访问时，情况有所不同。绕过缓存的结果比使用缓存的结果要慢得多（0.16s，约225MB/s）。在这里我们可以看到不可能进行写合并，并且每个存储单元都必须单独寻址。这需要在RAM芯片中不断地选择新行，并伴随所有相关的延迟。结果比缓存的运行结果差25％。

在读取方面，直到最近，除了使用非临时访问（NTA）预取指令的弱提示之外，处理器都缺乏支持。读取操作中没有等同于写合并的方法，这对于不可缓存的内存（例如内存映射的I/O）尤其不利。英特尔通过SSE4.1扩展引入了NTA负载。 它们使用少量的流式加载缓冲区（streaming load buffers）来实现。每个缓冲区包含一个缓存行。给定高速缓存行的第一条movntdqa指令会将高速缓存行加载到缓冲区中，可能会替换另一条高速缓存行。后续的16字节对齐访问同一高速缓存行将以很小的成本从加载缓冲区进行服务。除非有其他原因，否则高速缓存行将不会加载到高速缓存中，从而可以加载大量内存而不会污染高速缓存。 编译器为此指令提供了一个内在函数：

```c
#include <smmintrin.h>
__m128i _mm_stream_load_si128 (__m128i *p);
```

此内在函数应多次使用，并以16字节块的地址作为参数传递，直到读取每个高速缓存行。 只有这样，才能启动下一个缓存行。由于有一些流读取缓冲区，因此有可能一次从两个内存位置读取数据。

我们应该从该实验中了解到的是，现代CPU可以很好地优化未缓存的写访问和（最近的）读访问，只要它们是顺序的即可。当处理仅使用一次的大型数据结构时，此知识会非常有用。其次，缓存可以帮助掩盖内存随机访问的部分（但不是全部）成本。因为RAM的访问实现对随机访问不友好，本示例中的随机访问速度比顺序访问慢了70％。在实现更改之前，我们应尽可能避免使用随机访问。

在有关预取的部分中，我们将再次查看非临时标志。

## 6.2 访问高速缓存

程序员对缓存所能做的最重要的改进是那些影响一级缓存的改进。在包括其他级别之前，我们将首先讨论它。显然，针对1级缓存的所有优化也会影响其他缓存。所有内存访问的主题都是相同的：改进空间和时间局部性并对齐代码和数据。

### 6.2.1 优化一级 数据 缓存访问

在第3.3节中，我们已经看到有效使用L1d缓存可以提高性能的程度。在本节中，我们将显示哪些类型的代码更改可以帮助提高性能。在上一节的基础上，我们首先集中精力进行顺序访问内存的优化。如第3.3节中的数字所示，当顺序访问存储器时，处理器会自动预取数据。

使用的示例代码是矩阵乘法。我们使用两个1000×1000元素的正方形矩阵。给定两个矩阵A和B且元素 aij 和 bij 的`0 ≤ i,j < N` 则乘积为

![矩阵乘法1](https://static.lwn.net/images/cpumemory/matrixmult.png)

一个简单的C实现可以是这样的:

``` c
for (i = 0; i < N; ++i) // 计算每个元素，顺序访问mul1，随机访问mul2
  for (j = 0; j < N; ++j)
    for (k = 0; k < N; ++k)
      res[i][j] += mul1[i][k] * mul2[k][j];
```

两个输入矩阵是mul1和mul2，结果矩阵res被初始化为所有元素都是零。这是一个漂亮而简单的实现。但是很明显，我们确实遇到了图6.1中解释的问题。当按顺序访问mul1时，内循环将按列访问mul2。这意味着mul1的处理方式与图6.1中的左矩阵类似，而mul2的处理方式与右矩阵类似。也就是说mul2按随机访问，这不是好事。

有一种可能的补救方法可以很容易地尝试。因为矩阵中的每个元素都被多次访问，所以在使用第二个矩阵mul2之前，有必要重新排列(用数学术语来说就是“转置”)。

![矩阵乘法2](https://static.lwn.net/images/cpumemory/matrixmultT.png)

在转置(传统上用上标“T”表示)之后，我们现在依次遍历两个矩阵。就C代码而言，它现在看起来是这样的:

```c
double tmp[N][N];
for (i = 0; i < N; ++i) // 顺序访问mul2，保存其转置矩阵
  for (j = 0; j < N; ++j)
    tmp[i][j] = mul2[j][i];
    
  for (i = 0; i < N; ++i) // 计算每个元素，顺序访问mul1和mul2的转置
    for (j = 0; j < N; ++j)
      for (k = 0; k < N; ++k)
        res[i][j] += mul1[i][k] * tmp[j][k];
```

我们创建一个临时变量来包含转置矩阵。这需要占用更多的内存，但是由于每列1000次非顺序访问更昂贵（至少在现代硬件上），因此希望可以收回此成本。是时候进行一些性能测试了，在具有2666MHz时钟速度的英特尔酷睿2上的结果是(时间单位为时钟周期):

|  | 原矩阵 | 转置后 |
| --- | --- | --- |
| 时钟周期数 | 16,765,297,870 | 3,922,373,010 |
| 相对时间 | 100% | 23.4% |

通过简单的矩阵变换，速度提升了76.6%！额外的复制操作是并没有给性能拖后腿。1000次非顺序访问的性能真的很糟糕。

下一个问题是，这是不是我们能做到的最好水平。我们当然需要另一种不需要额外的副本的方法。我们并不总是能够奢侈地执行复制：矩阵可能太大，或者可用内存太小。

在寻找替代实现时，应该首先仔细检查原始实现所涉及的数学和原始实现中的操作。简单的数学知识可以让我们看到，在计算结果矩阵的每一个元素时，只要每个加数恰好出现一次，那么每个加数进行加法运算的顺序是无关紧要的（不考虑算术过程中可能会出现的上溢出、下溢出和舍入）。这种理解使我们能够寻找对原始代码的内循环中执行的加法进行重新排序的解决方案。

现在让我们检查一下原始代码执行中的实际问题。 mul2元素的访问顺序为：（0,0），（1,0），...，（N-1,0），（0,1），（1,1），...。 元素（0,0）和（0,1）位于同一高速缓存行中，但是，当内部循环完成一轮时，此高速缓存行早已被逐出。对于此示例，对于三个矩阵中的每个矩阵，内部循环的每一轮都需要1000个缓存行（对于Core 2处理器，需要64个字节）。这加起来比可用的L1d的32k要多得多。

但是如果我们在执行内部循环时同时处理中间循环的两次迭代呢? 在这种情况下，我们使用来自缓存行的两个double值，这些值保证在L1d中。我们将L1d错过率降低了一半。这当然是一种改进，但是，根据缓存行的大小，它可能仍然不如我们所能得到的好。Core 2处理器的L1d高速缓存行大小为64字节，实际值可以通过以下方式查询

```c
sysconf (_SC_LEVEL1_DCACHE_LINESIZE)
```

在运行时或从命令行使用getconf工具，让我们可以为特定的缓存行大小编译程序。如果sizeof（double）为8，这意味着要充分利用缓存行，我们应该将中间循环展开8次。沿着这个思路继续，同样要有效地使用res矩阵，即同时写入8个结果，我们也应该将外部循环展开8次。我们在这里假定大小为64的高速缓存行，但是该代码在具有32字节高速缓存行的系统上也能很好地工作，因为两条高速缓存行也都被100％使用。通常，最好在编译时使用getconf工具对高速缓存行大小进行硬编码，如下所示：

```c
gcc -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ...
```

如果二进制文件应该是通用的，那么应该使用最大的缓存行大小。对于非常小的L1ds，这可能意味着不是所有的数据都适合缓存，但是这样的处理器无论如何都不适合高性能程序。我们得到的代码看起来像这样：

``` c
#define SM (CLS / sizeof (double))

for (i = 0; i < N; i += SM)
  for (j = 0; j < N; j += SM)
    for (k = 0; k < N; k += SM)
      for (i2 = 0, rres = &res[i][j],rmul1 = &mul1[i][k];
           i2 < SM; ++i2, rres += N, rmul1 += N)
        for (k2 = 0, rmul2 = &mul2[k][j];
             k2 < SM; ++k2, rmul2 += N)
          for (j2 = 0; j2 < SM; ++j2)
            rres[j2] += rmul1[k2] * rmul2[j2];
```

这看起来很吓人。在某种程度上，它的确如此，但仅仅是因为它包含了一些技巧。最明显的变化是我们现在有6个嵌套循环。外循环以SM为间隔进行迭代（缓存行大小除以sizeof（double））。这将乘法分为几个较小的问题，可以用更多的缓存局部性来处理。内部三个循环遍历外部三个循环间隔部分的索引。这里唯一棘手的部分是k2和j2循环的顺序不同。这样做是因为在实际计算中，只有一个表达式取决于k2，而两个表达式取决于j2。

这里的其他复杂性来自这样一个事实：gcc在优化数组索引方面不是很聪明。额外变量rres、rmul1和rmul2的引入通过将公共表达式从内部循环中尽可能地提取出来优化代码。C和c++语言的默认别名规则不能帮助编译器做出这些决定(除非使用了restrict[如何理解C语言关键字restrict？](https://www.zhihu.com/)，否则所有指针访问都是潜在的别名来源)。这就是为什么Fortran仍然是数字编程的首选语言：它使编写快速代码更容易。从理论上讲，1999年修订版中引入的 restrict 关键字应该可以解决这个问题。然而，编译器还没有赶上来。主要原因是现存的错误代码太多，会误导编译器，导致编译器生成错误的目标代码。

所有这些工作是如何得到回报的可以在表6.2中看到。

|  | 原矩阵 | 转置后 | Sub-Matrix | Vectorized |
| --- | --- | --- | --- | --- |
| 时钟周期数 | 16,765,297,870 | 3,922,373,010 | 2,895,041,480 | 1,588,711,750 |
| 相对时间 | 100% | 23.4% | 17.3% | 9.47% |
**表6.2：矩阵乘法耗时**

通过避免复制，我们又获得了6.1％的性能。另外，我们不需要任何额外的内存。只要结果矩阵也适合内存，输入矩阵就可以任意大。这是我们现在实现的普遍解决办法的要求。

表6.2中还有一列没有解释。现在，大多数现代处理器都包含对向量化（Vectorized）的特殊支持。通常被称为多媒体扩展，这些特殊指令允许同时处理2、4、8或更多的值。这些操作通常是SIMD(单指令，多数据)操作，通过其他操作来获得正确形式的数据。英特尔处理器提供的SSE2指令可以在一次操作中处理两个double类型的值。指令参考手册列出了使用这些SSE2指令的内部函数。如果使用了这些特性，程序运行速度会比原来的更快上7.3%。其结果是，程序的运行时间仅为原始代码的10%。换算成人们能认出的数字，我们从318兆次拖减到了3.35兆次拖。因为我们这里只对内存效应感兴趣，所以程序代码包含在第9.1节。

应该注意的是，在最新版本的代码中，mul2仍然存在一些缓存问题。预取仍然无法进行。但是，如果不对矩阵进行转置，这是无法解决的。也许缓存预取单元会变得更聪明以识别我们的访问模式，那么就不需要进行其他更改。无论如何3.19 GFLOPS的结果对于在2.66 GHz处理器上的单线程代码也不错了。

在矩阵乘法示例中，我们优化的方法是使用已加载的缓存行。已加载缓存行的所有字节都被用到。我们只是确保在撤消缓存行之前就已使用它们。这当然是个特例。

事实上，更常见的情况是，数据结构占据一个或多个高速缓存行，且程序运行时在任意时间点只使用其中的几个成员。在图3.11中，我们已经看到如果只使用大型数据结构中的几个成员会产生什么影响。

![图6.2：分布在多条缓存行中的数据结构](https://static.lwn.net/images/cpumemory/cpumemory.37.png)
**图6.2：分布在多条缓存行中的数据结构**

图6.2显示了另一组基准测试的结果，这个基准使用了目前广泛使用的程序。我们将一个列表中的两个元素值进行相加。第一种情况是两个元素都在同一个缓存行中；另一种情况，一个元素位于列表元素的第一行缓存中，第二个元素位于最后一个缓存行中。该图显示了我们记录下的性能下降程度。

毫不奇怪，当L1d能容纳工作集时，在所有情况下都不会产生负面影响。而一旦L1d不再足够，将在处理中使用两条高速缓存行而不是一条，这会带来性能下降惩罚。红线表示测试数据列表在内存中顺序排列时的测试数据。我们看到了通常的两步模式：使用L2高速缓存时大约17％的性能损失，而必须使用内存时大约27％的性能损失。

随机内存访问测试用例的测试结果看起来有些不同。随机访存用例下，使用L2高速缓存的工作集的性能相比L1降低了25％至35％。在这之后，它性能下降的幅度降低到大约10％。这不是因为性能惩罚变小了，而是因为实际内存访问的变得格外昂贵。测试结果还表明，在某些情况下，元素之间的距离也会对性能产生影响。随机4CLs曲线显示出更高的惩罚，因为使用了第一和第四高速缓存行。

与缓存行相比，查看数据结构布局的一种简单方法是使用pahole工具（请参阅[dwarves]）。该程序检查以二进制形式定义的数据结构。观察一个包含以下定义的程序

``` c
struct foo {
  int a;
  long fill[7];
  int b;
};
```

在64位机器上编译后，pahole的输出包含了图6.3所示的信息。

```c
struct foo {
        int          a;                    /*     0     4 */
        
        /* XXX 4 bytes hole, try to pack */
        
        long int     fill[7];              /*     8    56 */
        /* --- cacheline 1 boundary (64 bytes) --- */
        int          b;                    /*    64     4 */
}; /* size: 72, cachelines: 2 */
   /* sum members: 64, holes: 1, sum holes: 4 */
   /* padding: 4 */
   /* last cacheline: 8 bytes */
```

**图 6.3: pahole 工具的输出**

这个输出包含了很多信息。首先，该数据结构使用了不止一个缓存行。该工具假定当前处理器的缓存行大小，也可以通过命令行参数设置此值。特别是在数据结构的大小刚好超过某个缓存行的大小限制，并且分配了许多此类对象的情况下，寻找一种压缩该数据结构大小的方法是有意义的。也许某些元素可以使用更小的数据类型，或者某些字段是一个“y or n”的标志，这种标志可以只用一个bit位表示。

示例中数据结构很容易压缩，并且工具提示了如何进行压缩。工具的输出显示在第一个元素之后有一个四个字节的空洞。该空洞是由数据结构元素放置的数据对齐行为引起的。显而易见，元素b的大小为4个字节（在行的末尾由4表示），可以完美的放置在空洞里。压缩优化之后，空洞就不存在了，并且整个数据结构只需要一条高速缓存行。Pahole工具本身可以执行此优化。如果使用了-reorganize参数，并且在命令行末尾添加了数据结构名称，工具的输出中就会将数据结构进行优化。除了移动元素以填充空洞外，该工具还可以优化位字段并将“padding”和空洞相结合。更多详细信息，请查看[dwarves]。

当然，理想的情况是有一个足够大的空洞来容纳后面的元素。为了实现这种优化，需要将对象本身与高速缓存行对齐。我们马上就会讲到。

通过pahole输出，还可以更轻松地确定是否要对数据结构的元素进行重新排序，以便使一起使用元素被存储在一起。使用pahole工具，可以轻松地确定哪些元素在同一高速缓存行中，以及何时需要重新组合元素才能实现这一目的。这不是一个自动过程，但是该工具可以提供很多帮助。

各个结构元素的位置及其使用方式也很重要。正如我们在3.5.2节中所看到的那样，在高速缓存行中带有关键单词（critical word）的代码的性能更差。这意味着程序员应始终遵循以下两个规则：

1. 始终将最有可能成为关键单词的元素移到数据结构开头。
2. 当访问数据结构时，如果访问顺序不受限制，请按在数据结构中定义元素的顺序访问元素。

对于小型结构，这意味着程序员应按可能访问元素的顺序排列元素。必须以灵活的方式处理此问题，以允许同时应用其他优化（例如空洞填充）。对于更大的数据结构，数据结构中每个缓存行大小的区域都应按照这种规则进行排列。

但是，如果对象本身未对齐，则花费时间进行重新排序是没有作用的。对象的对齐方式由数据类型的对齐要求决定。每种基本数据类型都有其自己的对齐要求。对于结构化类型，其中元素的最大对齐要求决定了整个结构类型的对齐方式。所以结构化类型的对齐要求总是小于高速缓存行的大小。这意味着即使将结构的成员对齐在同一条缓存行内，分配的对象也可能没有按照与缓存行大小匹配方式对齐。有两种方法可以确保对象具有设计结构布局时使用的对齐方式：

**对象分配时可以明确指定对齐要求**
动态分配，调用malloc进行动态内存分配时，得到的对象的对齐方式与最苛刻的标准类型（通常为long double）匹配。但是，可以使用posix_memalign来请求更高的对齐方式。

``` c
#include <stdlib.h>
int posix_memalign(void **memptr, size_t align, size_t size);
```

该函数将指向新分配的内存的指针存储在memptr指向的指针变量中，内存的大小为`size`字节，并对齐到`align`字节。

对于由编译器分配的对象（在.data，.bss等中，以及在堆栈上），可以使用变量属性：

``` c
struct structtype variable __attribute((aligned(64)));
```

在这种情况下，无论`structtype`结构的对齐要求如何，`variable`都会对齐到64字节。这种方法适用于全局变量和自动变量。

但是，此方法不适用于数组。除非每个数组元素的大小是对齐值的整数倍，否则只有数组的第一个元素会对齐。这也意味着必须对数组中的每个元素都应用此标识。posix_memalign的使用也是有额外开销的，因为对齐要求通常会导致内存碎片和更高的内存消耗。

**结构化类型的对齐要求可以使用类型属性更改:**

``` c
struct structtype {
    ...members...
  } __attribute((aligned(64)));
```

这将导致编译器按我们要求的对齐方式分配对象，分配数组时也一样。必须注意的是，在动态分配内存时，程序员仍然需要使用posix_memalign为内存设置适当的对齐方式。我们可以很容易地使用gcc提供的alignof运算符得到结构体的对齐要求，并将该值作为第二个参数传递给posix_memalign函数。

本节前面提到的多媒体扩展几乎总是要求对齐内存访问。即，对于16字节的内存访问，其内存地址应该是16字节对齐的。x86和x86-64处理器的内存操作的支持处理未对齐的访问，但速度较慢。在大多数RISC体系结构中，要求对所有内存的访问都是完全对齐的，上述的严苛对齐要求对于它们来说并不是什么新鲜事。即使架构支持不对齐的访问，这有时也比使用适当的对齐要慢，特别是如果不对齐导致装入或存储使用两条缓存行而不是一条缓存行。

![图6.4：未对齐访问的开销](https://static.lwn.net/images/cpumemory/cpumemory.48.png)
**图6.4：未对齐访问的开销**

图6.4显示了未对齐内存访问的影响。我们的测试方法是，（顺序或随机）访问内存中的列表数据元素，并增加数据元素的值，先测试列表元素对齐时的性能，再测试列表元素故意不对齐时的性能。该图显示了由于未对齐访问而导致的程序速度下降。对于顺序访问的情况，其影响要比对随机情况的影响更为显著，因为随机访问的内存访问开销太大了，一定程度上掩盖了未对齐访问的开销。在顺序情况下，对于需要使用L2高速缓存的工作集大小，性能降低了大约300％，这是因为此时L1缓存的有效性降低了。现在，某些增加操作涉及两条高速缓存行，并且在列表元素上工作通常需要读取两条高速缓存行。L1和L2之间的连接太拥挤了。

对于非常大的工作集，未对齐访问仍然造成了20％到30％的性能降低，考虑对大型工作集的对齐访问时间已经很长了，多出来的20%到30%是很大的。该图应表明必须认真对待对齐。即使架构支持未对齐的访问，也不能将其视为“与对齐的访问一样好”。

不过，这些对齐要求也有一些附带影响。如果自动变量有对齐要求，编译器必须确保在所有情况下都满足该要求。这不是小事，因为编译器无法控制调用位置和它们处理堆栈的方式。这个问题可以通过两种方式来解决：

1. 生成的代码会主动对齐堆栈，并在必要时插入空白。这需要代码来检查对齐、创建对齐，然后撤消对齐。
2. 要求所有调用者对齐堆栈。

所有常用的应用程序二进制接口（ABI）都遵循第二条路线。如果调用者违反规则并且需要在被调用者中进行对齐，则程序可能会失败。但是，保持对齐完整并非免费的。

函数中使用的堆栈框架的大小不一定是对齐的倍数。这意味着，如果从此堆栈帧中调用其他功能，则需要填充。 最大的区别是，在大多数情况下，编译器都知道堆栈帧的大小，因此，它知道如何调整堆栈指针以确保从该堆栈帧调用的任何函数的对齐方式。实际上，大多数编译器会简单地舍入堆栈帧的大小并使用它来完成。

如果使用可变长度数组（VLA）或alloca，则无法使用这种简单的对齐方式。在这种情况下，仅在运行时才知道堆栈帧的总大小。在这种情况下，可能需要主动对齐控制，从而使生成的代码（稍微）变慢。

在某些体系结构上，仅多媒体扩展需要严格对齐。这些架构上的堆栈对于常规数据类型始终保持最小对齐，对于32位和64位架构，通常分别为4或8字节对齐。在这些系统上，强制对齐会产生不必要的成本。这意味着，在本例中，如果我们知道程序没有依赖多媒体扩展，我们可能想要摆脱严格对齐要求。不执行多媒体操作的尾函数（指不调用其他函数的函数）不需要对齐。仅调用不需要对齐的函数的函数也不需要对齐。如果程序中上面两种函数很多，则程序可能希望放宽对齐要求。对于x86二进制文件，gcc支持宽松的堆栈对齐要求：

``` shell
-mpreferred-stack-boundary=2
```

如果将此选项的值设置为N，则堆栈对齐要求将设置为 2^N 个字节。因此，如果使用值2，则堆栈对齐要求将从默认值（16字节）减少到仅4字节。在大多数情况下，这意味着不需要额外的对齐操作，因为正常的堆栈压入和弹出操作无论如何都在四字节边界上进行。此机器特定的选项可以帮助减小代码大小，并提高执行速度。但是它不能应用于许多其他体系结构。即使对于x86-64，它也通常不适用，因为x86-64 ABI要求在SSE寄存器中传递浮点参数，而SSE指令需要完整的16字节对齐。但是，任何时候只要设置了这个选项，都会产生显着的不同。

数据结构中元素的有效放置和对齐并不是影响数据结构的高速缓存效率的唯一方面。如果使用结构体数组，则整个结构体定义都会影响性能。记住图3.11中的结果：在这种情况下，数组元素中的未使用数据量不断增加。结果是，预取的效率越来越低，并且针对大型数据集的程序的效率也越来越低。

对于大型工作集，尽可能使用可用的缓存非常重要。为此，可能需要重新安排数据结构。虽然程序员更容易将概念上属于同一类的所有数据放到同一个数据结构中，但这可能不是实现最佳性能的方法。假设我们的数据结构如下：

``` c
struct order {
  double price;
  bool paid;
  const char *buyer[5];
  long buyer_id;
};
```

进一步假设这些记录存储在一个很大的阵列中，并且有一个频繁运行的任务计算所有未支付的账单的总金额。在这种情况下，存储Buyer和Buyer_id字段的内存应该不必加载到缓存中。从图3.11中的数据来看，该程序的性能可能会比其可能达到的最佳性能差5倍。

更好的方法是将订单数据结构一分为二，前两个字段存储在一个结构中，其他字段存储在另一个结构中。这种变化肯定会增加程序的复杂性，但是性能的提高可能能够证明这一成本是合理的。

最后，让我们考虑另一个缓存使用优化，该优化同时也适用于其他缓存，主要体现在L1d访问中。就像我们在图3.8中看到的那样，高速缓存关联性的增强有利于正常操作。通常高速缓存越大，关联性就越高。L1d高速缓存太大，无法完全关联（fully associative），但又不足以与L2高速缓存具有相同的关联性。如果工作集中的许多对象都属于同一个缓存集中，就可能会产生问题。如果由于过度使用缓存集合而导致逐出，即使仍有许多缓存未使用，程序也可能会遇到延迟。这些高速缓存未命中有时称为冲突未命中（conflict misses）。由于L1d寻址使用虚拟地址，因此实际上程序员可以对此进行控制。如果一起使用的变量也一起存储，则将它们归入同一高速缓存集合的可能性就能降到最低。图6.5显示了问题发生的速度。

![图6.5：缓存关联性影响](https://static.lwn.net/images/cpumemory/cpumemory.69.png)
**图6.5：缓存关联性影响**

在图中，现在我们将熟悉的{测试在32位机器上运行，因此NPAD=15表示每个列表元素占用一个64字节的缓存行}NPAD=15 测试进行特殊的设置。X轴是两个列表元素之间的距离，以空列表元素度量。换句话说，距离为2意味着下一个元素的地址在前一个元素地址之后的128字节。列表中所有元素都以相同的距离布置在虚拟地址空间中。Y轴表示列表的总长度。只使用1到16个元素，这意味着工作集的总大小是64到1024字节。z轴表示遍历每个列表元素所需的平均周期数。

图中所示的结果并不令人惊讶。如果使用很少的元素，那么所有的数据都会放入L1d，每个列表元素的访问时间只有3个周期。几乎所有列表元素的排列都是如此：虚拟地址很好地映射到L1d插槽，几乎没有冲突。在此图中，有两个特殊的距离值，其情况不同。如果距离是4096字节的倍数（即64个元素的距离），并且列表的长度大于8，则遍历每个列表元素的平均周期数显著增加。在这些情况下，所有条目都在同一个集合中，一旦列表长度大于关联性，则从L1d刷新条目，并且必须在下一轮从L2重新读取条目。这将导致每个列表元素大约10个周期的开销。

通过此图，我们可以确定所使用的处理器具有关联性为8的L1d缓存，总大小为32kB。这意味着，如果必要的话，上述测试可以用来确定这两个值。同样的效果也可以在二级缓存中测量到，但是二级缓存更复杂，因为二级缓存是使用物理地址索引的，而且它要大得多。

对于程序员来说，这意味着关联性是值得注意的。在现实世界中，在2的指数幂的边界上布局数据的情况经常发生，但这正是容易导致上述影响和性能下降的情况。未对齐的访问会增加冲突未命中的概率，因为每个访问可能需要额外的缓存行。

![图6.6：AMD处理器上的L1d组地址](https://static.lwn.net/images/cpumemory/cpumemory.58.png)
**图6.6：AMD处理器上的L1d组地址**

如果执行此优化，也可以执行另一个相关优化。至少对AMD来说，处理器的L1d分为几个独立的组bank。如果两个数据字存储在不同的组或在同一组且具有相同索引，则L1d可以在每个时钟周期中接收两个数据字。如图6.6所示，组地址用虚拟地址的低位编码。如果我们将同时使用的变量也存储在一起，则它们位于不同组或具有相同索引的同一组的可能性很高。

### 6.2.2 优化一级 指令 缓存访问

为优化L1i的使用需要用到优化L1d类似的技术。但问题是，除非程序员用汇编语言编写代码，否则程序员通常不能直接影响L1i的使用方式。如果使用编译器，程序员还是可以通过引导编译器创建更好的代码布局来间接确定L1i的使用。

代码相比于数据有一个优势是代码在发生跳转（jump）之间是线性存储的。在跳转的间期内，处理器可以有效地预取内存。跳转会扰乱这番和谐的场景，因为

1. 跳转的目标可能不能被静态确定；
2. 即便可以静态确定跳转目标，如果所有缓存都未命中，那么获取内存可能需要很长时间。

这些问题会在执行过程中造成停顿，并可能严重影响性能。这就是为什么当今的处理器在分支预测（BP，branch prediction）上投入大量资金进行研发的原因。高度专业化的BP单元试图在跳转发生之前，尽可能早的时间确定跳转的目标，以便处理器可以开始将新位置的指令加载到缓存中。它们使用静态和动态规则，并且越来越善于确定执行模式。

对于指令高速缓存而言，尽快将数据放入高速缓存更为重要。如第3.1节所述，在执行指令之前必须先对其进行解码，并且为了加快执行速度（在x86和x86-64上非常重要），指令在高速缓存中实际上以已解码形式，而不是以内存中读出来的字节或字（byte/word）形式存放。

为了实现最佳的L1i使用，程序员至少应注意代码生成的以下三个方面：

1. 尽可能减少代码占用量。这个需求必须与诸如循环展开和内联（inlining）之类的优化方法相平衡。
2. 代码执行应该是线性的，没有气泡。{气泡图形化地描述了处理器流水线（pipeline）在执行过程中的遇到的空洞（hole），当执行必须等待资源时会出现这些空洞。有关详细信息，请参阅有关处理器设计的文献。}
3. 在适当的时候对齐代码。

下面我们来看一些可从这三个方面帮助程序优化的编译器技术。

编译器具有一个选项用来选择优化级别，特定的优化级别也可以单独使用。在高优化级别（比如gcc为-O2和-O3）启用的许多优化都涉及循环优化和函数内联。通常，这些优化都很好。如果以这些方式优化的代码占程序总执行时间的很大一部分，则可以提高整体性能。特别地，函数内联允许编译器一次优化更大的代码块，从而可以使生成的机器代码更好地利用处理器的流水线体系结构。当可以将程序的较大部分视为一个单元时，对代码和数据的处理（通过消除无效代码或值域传播以及其他方法）效果更好。

更长的代码意味着对L1i（以及L2和更高级别）高速缓存的压力更高。这会导致性能降低。更短的代码可以运行得更快。幸运的是，gcc有一个优化选项可以指定此项。如果使用-Os，则编译器将优化代码大小。使用后，能够增加代码大小的哪些优化将被禁用。使用此选项通常会产生令人惊讶的结果。特别是循环展开和内联没有实质优势时，那么此选项将是一个很好的选择。

内联也可以单独控制。编译器具有指导内联的启发式方法和限制。这些限制可以由程序员控制。`-finline-limit`选项指定函数达到多大时就认为其不能进行内联。如果在多个位置调用一个函数，则在所有位置内联该函数会导致代码大小激增。但是还有更多。假设函数inlcand在两个函数f1和f2中被调用。函数f1和f2本身被依次调用。

``` shell
// With inlining       Without inlining
start f1               start inlcand
  code f1                code inlcand
  inlined inlcand      end inlcand
  more code f1
end f1                 start f1
                         code f1
start f2               end f1
  code f2
  inlined inlcand      start f2
  more code f2           code f2
end f2                 end f2
```
**表 6.3: 使用内联函数和不使用内联函数**

表6.3展示了在不使用内联和两个函数使用内联的情况下编译器生成的代码。如果在f1和f2中都使用内联函数inlcand，则生成的代码的总大小为：`size f1 + size f2 + 2 × size inlcand`

如果不使用内联函数，代码总大小会减少inlcand函数的大小。当f1和f2在短时间内接连被调用，使用内联函数也会多需要这么大的L1i和L2高速缓存。另外的，如果不使用内联函数，在f2中调用inlcand时，inlcand的代码可能仍在L1i中，无需再次加载并解码了。而且，分支预测单元也可能预测得更好，因为它已经看到incland的代码了。如果编译器默认的内联函数大小上限不是最适合该程序的值，它就应该被减小。

但是，在某些情况下，内联总是有意义的。如果一个函数仅被调用一次，则最好内联。 这使编译器有机会执行更多优化（例如值域传播，这可能会大大改善代码）。选择限制（selection limits）可能会阻止内联优化。在这种情况下，gcc具有一个选项，用于指定函数始终作为内联函数。给函数添加`always_inline`函数属性可使编译器的行为完全按照这个属性的名字描述的那样。

在相同的上下文中，如果函数在足够小时也不想使用内联，则可以使用noinline函数属性。如果函数经常从不同地方调用，那么对小型函数使用此属性也是有意义的。如果可以重复使用L1i内容并且整体代码占用空间减小了，那么这通常可以弥补不使用内联带来的额外函数调用开销。如今，分支预测单元的效果已经非常好了。如果内联可以导致更积极的优化，则情况将有所不同。这是必须根据具体情况决定的。

如果始终使用内联代码，则`always_inline`属性可以很好地工作。但是，如果不是这种情况怎么办？ 如果仅偶尔调用内联函数会怎么样呢：

```c
void fct(void) {
  ... code block A ...
  if (condition)
    inlfct()
  ... code block C ...
}
```

通常编译器生成代码的顺序与源代码的结构匹配。这意味着首先是代码块A，然后是条件跳转，如果条件为假，则条件跳转将向前跳转。接下来是为内联的inlfct函数生成的代码，最后是代码块C。在着起来很合理的行为含有隐藏的问题。

当`condition`经常为假时，执行过程就不是线性的了。中间有很多未使用的代码，这不仅会在预取时污染L1i，而且还会引起分支预测的问题。如果分支预测错误，则条件表达式的效率可能非常低。

这是一个普遍的问题，并不仅限于使用内联函数时。每当使用条件语句且条件选择不均衡时（即该表达式更容易选择一遍执行），就有可能导致错误的静态分支预测，从而在流水线中产生气泡。这个问题可以通过让编译器将执行频率较低的代码移出主代码路径来预防。在这种情况下，为if语句更不容易选择的路径生成的条件分支将跳到主路径顺序之外的位置，如下图所示。

![代码布局](https://static.lwn.net/images/cpumemory/cpumemory.38.png)

图的上面部分代表通常情况下的简单代码布局。如果区域B（这里是内联函数inlfct生成的代码）经常由于条件I被跳过，而不会执行，处理器的预取将拉入很少使用的包含块B的高速缓存行。使用块重新排序可以改变这种局面，改变之后的效果可以在图的下半部分看到。经常执行的代码在内存中是线性的，而很少执行的代码被移动到不会损害预取和L1i效率的位置。

gcc提供了两种方法来实现此目的。首先，编译器可以在重新编译代码时考虑分析输出，并根据配置文件对代码块进行布局。我们将在第7节中看到这是如何工作的。第二种方法是通过显式分支预测。gcc 提供了 `__builtin_expect`：

```c
long __builtin_expect(long EXP, long C);
```

该结构告诉编译器，表达式EXP最有可能具有值C。返回值为表达式EXP。 `__builtin_expect`用于条件表达式。在几乎所有情况下，都将在布尔表达式的上下文中使用它，在这种情况下，定义两个帮助程序宏将更加方便：

```c
#define unlikely(expr) __builtin_expect(!!(expr), 0)
#define likely(expr) __builtin_expect(!!(expr), 1)
```

这些宏可以像下面这样使用

```c
if (likely(a > 1))
```

如果程序员利用这些宏，然后使用-freorder-blocks优化选项，则gcc将对块进行重新排序，如上图所示。 该选项在-O2中启用，但在-Os中禁用。还有另一种对块进行重新排序的选项（-freorder-blocks-and-partition），但是它的用处有限，因为它不适用于异常处理。

至少在某些处理器上，小循环还有另一个很大的优势。英特尔酷睿2前端具有一项特殊功能，称为循环流检测器（LSD，Loop Stream Detector）。如果一个循环中的指令不超过18条（都不是对子程序的调用），只需要4译码器读取16字节，最多具有4条分支指令，并且比该循环执行64次以上，则有时它会被锁定在指令队列中，以便于在再次使用它时可以更快地可用。例如，这适用于通过外部循环多次进入的小的内部循环。即使没有这种专门的硬件，紧凑的循环也具有优势。

内联不是关于L1i优化的唯一方面。另一个方面是对齐，就像数据一样。和数据不同的是，代码是一个主要为线性分布的二进制类型大对象（Blob，Binary Large Object），不能随意放置在地址空间中，也不能在编译器生成代码时受到程序员的直接影响。不过，也有一些方面是程序员可以控制的。

对齐每条指令是没有意义的。我们的目的是使指令流是顺序执行的。因此，在关键的地方进行对齐才有意义。要决定在什么地方进行对齐，必须了解对齐会带来什么优势。在高速缓存行的开头放置指令{对于某些处理器，高速缓存行不是指令的原子块。英特尔酷睿2前端向解码器发出16个字节的块。它们已适当对齐，因此没有已发布的块可以跨越高速缓存行边界。在高速缓存行的开头对齐仍然具有优势，因为它可以优化预取的积极效果。}意味着可以最大化高速缓存行的预取。对于指令，这也意味着解码器更有效。不难看出，如果执行了高速缓存行末尾的指令，则处理器必须准备好读取新的高速缓存行并对指令进行解码。有些事情可能出错（例如高速缓存行未命中），这意味着平均而言，高速缓存行末尾的指令执行效率不如高速缓存行开头的有效。

将其与后续推论相结合，即如果将控制权仅仅转移到有问题的指令上，则问题将最为严重（因此预取是无效的），我们得出了关于在哪里进行代码对齐最为有用的最终结论：

1. 在函数开始时；
2. 在仅通过跳转到达的[基本块（basic block）](https://en.wikipedia.org/wiki/Basic_block)的开始处；
3. 在某种程度上，在循环的开始。

在前两种情况下，对齐的开销很少。当在一个新的位置继续执行代码时，如果我们将新的位置选择在高速缓存行的开头，则会优化预取和解码。{对于指令解码，处理器通常使用比高速缓存行大小更小的单位，在x86和x86-64的情况下为16字节。}编译器通过在由对齐方式产生的空白中插入一系列空指令（no-op instructions）来实现对齐。这些“无效代码（dead code）”会占很小的空间，通常不会影响性能。

第三种情况稍有不同：对齐每个循环的开始可能会产生性能问题。循环开头通常是顺序跟随其他代码之后的。如果情况不是很幸运，前序指令和对齐的循环开头之间会有一个间隙。与前两种情况不同，这种间隙不是完全没有意义的。在执行完前一条指令之后，循环中的第一条指令必须被执行。这意味着，在前面的指令之后，要么必须有大量的空指令来填补对齐产生的间隙，要么必须有一跳无条件跳转指令跳转到循环的开始。这两种方式都有其相应的开销。特别是在循环本身不经常执行的情况下，通过调整循环，空指令或跳转的代价可能让对齐得不偿失。

程序员可以通过三种方式影响代码的对齐方式。显然，如果代码是用汇编写的，则函数及其中的所有指令都可以显式对齐。汇编程序为所有体系结构提供`.align`伪操作(pseudo-op)来实现对齐。对于高级语言，必须告知编译器对齐要求。与数据类型和变量不同，这在源代码中是不可能的。而是使用编译器选项：

``` shell
-falign-functions=N
```

此选项指示编译器将所有函数与其下一个大于N的2的幂的边界对齐。这意味着将创建最多N个字节的间隙。对于较小的函数或很少用到的代码，使用较大的N值是浪费的。库中经常会有一些接口是频繁使用的，而另一些是很少使用的。合理的选择这个配置项的值可以避免对齐，从而加快运行速度和节省内存。当N的值为1或使用`-fno-align-functions`选项时，编译器将不进行对齐。

上面第二种情况的对齐方式，（不能通过顺序执行到达的基本块的起点）可以用另一个选项进行控制：

``` shell
-falign-jumps=N
```

所有其他使用细节都和上面第一个选项一样，关于内存浪费的风险也一样存在。

第三种情况也有其控制选项：

``` shell
-falign-loops=N
```

同样的，使用细节和内存分析也一样。除此以外，如前所述，对齐后存在额外的运行时间，因为指令的顺序执行，必须执行空指令或跳转指令。

gcc还有另一个控制对齐的选项，这里仅出于完整性目的而提及它。`-falign-labels`对齐代码中的每个单个标签（single label），基本上指每个基本块的开头。除了少数例外情况，这会减慢代码的速度，因此不应该使用。

### 6.2.3 优化二级以及更高层级缓存的访问

上面描述的所有对于1级缓存的优化方法也适用于2级以及更高层级的缓存。对于最后一级缓存，还有额外的两个方面：

1. 高速缓存未命中总是非常昂贵的。一级缓存未命中时我们希望可以频繁地命中L2和更高的缓存，从而限制性能惩罚，但是最后一级缓存显然是没有后备选择的。
2. L2高速缓存和更高级别的高速缓存通常由多个内核和/或超线程共享。因此，每个执行单元可用的有效缓存大小通常小于总缓存大小。

为了避免高速缓存未命中的高成本，工作集大小应与高速缓存大小匹配。如果仅需要一次数据，则显然没有必要存在高速缓存中，因为无论如何缓存都不会命中。我们需要考虑的是那些包含多次使用的数据集的工作负载。在这种情况下，使用太大而无法放入高速缓存的工作集将导致大量的高速缓存未命中，即使成功执行了预取操作，也会使程序变慢。

即使数据集太大，程序也必须执行其工作。最大限度地减少缓存未命中是程序员的责任。对于最后一级的高速缓存，与L1高速缓存一样，可以通过将工作集分成小块来减少缓存未命中。这与表6.2上的矩阵乘法优化非常相似。但是，一个区别是，对于最后一级的高速缓存，要处理的数据块可能更大。如果还需要对L1优化，则代码变得更加复杂。想象一下矩阵乘法的例子中，其中数据集（两个输入矩阵和输出矩阵）不一起容纳在最后一级缓存中。在这种情况下，同时优化L1和最后一级缓存访问可能是合适的。

L1缓存行大小通常在许多代处理器中都是恒定的。即使不是，差异也会很小。假设缓存行为更大的尺寸没什么大问题。在具有较小高速缓存大小的处理器上，将使用两个或多个高速缓存行，而不是一个。无论如何，对高速缓存行大小进行硬编码并为此优化代码是合理的。

对于更高层级的缓存，如果程序是通用的，则不是这种情况。这些缓存的大小可以相差很大。最大和最小之间相差八倍或更多都不少见。我们不能假定较大的缓存大小为默认值，因为这意味着除了缓存最大的计算机之外，代码在所有计算机上的性能都很差。 相反的选择也很糟糕：假设最小的缓存意味着丢弃87％或更多的缓存。这是十分糟糕的，从图3.14中可以看到，使用大型缓存可能会对程序的速度产生巨大影响。

这意味着代码必须根据缓存行大小动态地进行自我调整。这是一个特定于程序的优化。我们在这里只能说程序员应该正确地计算程序的需求。不仅是程序需要的数据集，更高级的高速缓存还用于其他目的，例如，所有已执行的指令均从缓存中加载。如果我们正在使用库函数，则此缓存使用量可能总计很大。这些库函数可能还需要自己的数据，这进一步减少了可用内存。

一旦有了内存需求的公式，就可以计算出内存需求并将其与缓存大小进行比较。如前所述，缓存可能与其他多个内核共享。当前{肯定很快就会有更好的方法！}在不进行硬编码的情况下获取正确信息的唯一方法是通过`/sys`文件系统。在表5.2中，我们看到了内核开放出来的有关硬件的信息。应用程序可以在：`/sys/devices/system/cpu/cpu*/cache`目录中找到最后一级缓存的信息。该信息可以通过cache目录中的名为level的文件中的最大数值来确定。当识别到最后一级缓存信息所在的目录后，应用程序应读取该目录中名为size的文件的内容，并将数值除以文件`shared_cpu_map`中位掩码中设置的位数。

以这种方式计算的值是安全的下限。有时程序对其他线程或进程的行为了解的比较多。如果这些线程是在共享高速缓存的核心或超线程核心上调度的，并且已知高速缓存使用情况并未达到其在总高速缓存大小中所分配到的比例，则计算出的限制可能太低而无法达到最佳。是否应使用比分配到的份额更多的缓存确实取决于情况。程序员必须做出选择，或者必须允许用户做出决定。

### 6.2.4 优化TLB利用率

## 6.3 预取（Prefetching）
